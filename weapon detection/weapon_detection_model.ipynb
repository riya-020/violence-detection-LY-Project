{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKDEjMr3eTNW",
        "outputId": "cf8f0b73-8085-4d68-9fdd-e8a3f232717b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Available: True\n",
            "GPU Name: NVIDIA GeForce GTX 1650\n",
            "Using dataset path: C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# -----------------------------\n",
        "# GPU CHECK (VS Code version)\n",
        "# -----------------------------\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# -----------------------------\n",
        "# No Colab, no Drive\n",
        "# Set your local dataset path here\n",
        "# Example: r\"C:\\Users\\Jiya\\Documents\\weapon-dataset\"\n",
        "# -----------------------------\n",
        "DATASET_PATH = r\"C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\"\n",
        "\n",
        "print(\"Using dataset path:\", DATASET_PATH)\n",
        "assert os.path.exists(DATASET_PATH), \"❌ Dataset path not found! Fix the folder path.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiziLE4Qedmd",
        "outputId": "a4a8258c-9cc9-4724-c974-3ac91a7a4a68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset root: C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\n",
            "Working directory: C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "DATASET_ROOT = r\"C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\"\n",
        "# Set your dataset path (modify this to match your Drive structure)\n",
        "# ----------------------------------\n",
        "# Local working directory\n",
        "# This is where model weights, results, runs/ folders will be saved\n",
        "# ----------------------------------\n",
        "WORK_DIR = r\"C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\"\n",
        "\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Dataset root: {DATASET_ROOT}\")\n",
        "print(f\"Working directory: {WORK_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xjD4ZpMfUQ5",
        "outputId": "6a248afd-9b62-4b6b-b0db-be800cadce7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verifying dataset structure:\n",
            "Train images folder exists: True\n",
            "Train labels folder exists: True\n",
            "Val images folder exists: True\n",
            "Val labels folder exists: True\n",
            "\n",
            "Training images: 571\n",
            "Training labels: 571\n",
            "Validation images: 143\n",
            "Validation labels: 143\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Verify Dataset Structure (VS Code Version)\n",
        "# ============================================================================\n",
        "\n",
        "# Paths (these variables were defined in the previous cell)\n",
        "train_images = os.path.join(DATASET_ROOT, 'train', 'images')\n",
        "train_labels = os.path.join(DATASET_ROOT, 'train', 'labels')\n",
        "val_images = os.path.join(DATASET_ROOT, 'val', 'images')\n",
        "val_labels = os.path.join(DATASET_ROOT, 'val', 'labels')\n",
        "\n",
        "print(\"\\nVerifying dataset structure:\")\n",
        "print(f\"Train images folder exists: {os.path.exists(train_images)}\")\n",
        "print(f\"Train labels folder exists: {os.path.exists(train_labels)}\")\n",
        "print(f\"Val images folder exists: {os.path.exists(val_images)}\")\n",
        "print(f\"Val labels folder exists: {os.path.exists(val_labels)}\")\n",
        "\n",
        "# Count files safely\n",
        "def count_files(path, exts):\n",
        "    if not os.path.exists(path):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(path) if f.lower().endswith(exts)])\n",
        "\n",
        "if os.path.exists(train_images):\n",
        "    train_img_count = count_files(train_images, ('.jpg', '.png', '.jpeg'))\n",
        "    train_label_count = count_files(train_labels, ('.txt',))\n",
        "    print(f\"\\nTraining images: {train_img_count}\")\n",
        "    print(f\"Training labels: {train_label_count}\")\n",
        "\n",
        "if os.path.exists(val_images):\n",
        "    val_img_count = count_files(val_images, ('.jpg', '.png', '.jpeg'))\n",
        "    val_label_count = count_files(val_labels, ('.txt',))\n",
        "    print(f\"Validation images: {val_img_count}\")\n",
        "    print(f\"Validation labels: {val_label_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jCQEwblfkDC",
        "outputId": "cf1cd9cf-d44d-42f7-ad10-bab34319f9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CONVERTING DATASET TO SINGLE-CLASS FORMAT (weapon)\n",
            "================================================================================\n",
            "✓ Converted 571 training labels into class 0\n",
            "✓ Converted 143 validation labels into class 0\n",
            "\n",
            "All weapons are now labeled as: class 0 → 'weapon'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONVERTING DATASET TO SINGLE-CLASS FORMAT (weapon)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def convert_to_single_class(label_dir):\n",
        "    \"\"\"Convert every label file so all classes become class 0.\"\"\"\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "    converted = 0\n",
        "\n",
        "    for lf in label_files:\n",
        "        path = os.path.join(label_dir, lf)\n",
        "\n",
        "        new_lines = []\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    # Always convert class_id → 0\n",
        "                    x, y, w, h = parts[1:5]\n",
        "                    new_lines.append(f\"0 {x} {y} {w} {h}\\n\")\n",
        "\n",
        "        # Rewrite file in-place\n",
        "        with open(path, 'w') as f:\n",
        "            f.writelines(new_lines)\n",
        "\n",
        "        converted += 1\n",
        "\n",
        "    return converted\n",
        "\n",
        "\n",
        "train_converted = convert_to_single_class(train_labels)\n",
        "val_converted = convert_to_single_class(val_labels)\n",
        "\n",
        "print(f\"✓ Converted {train_converted} training labels into class 0\")\n",
        "print(f\"✓ Converted {val_converted} validation labels into class 0\")\n",
        "print(\"\\nAll weapons are now labeled as: class 0 → 'weapon'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "CREATING DATASET YAML (Single Class)\n",
            "================================================================================\n",
            "\n",
            "✓ Dataset YAML created at: C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_dataset_single_class.yaml\n",
            "\n",
            "path: C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 1\n",
            "names:\n",
            "- weapon\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Create Final YAML (Uses YOLO Built-In Augmentation)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING DATASET YAML (Single Class)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "data_yaml = {\n",
        "    'path': DATASET_ROOT,\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'nc': 1,\n",
        "    'names': ['weapon']\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(WORK_DIR, 'weapon_dataset_single_class.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data_yaml, f, sort_keys=False)\n",
        "\n",
        "print(f\"\\n✓ Dataset YAML created at: {yaml_path}\\n\")\n",
        "with open(yaml_path, 'r') as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xRIGDDeizx7",
        "outputId": "d599a852-d7e9-4e8a-afe8-8525e08e953f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checking GPU availability...\n",
            "CUDA available: True\n",
            "GPU: NVIDIA GeForce GTX 1650\n",
            "\n",
            "✓ Loaded YOLOv8 model: yolov8s.pt\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Initialize YOLOv8 Model (Local VS Code)\n",
        "# ============================================================================\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Check GPU\n",
        "print(\"\\nChecking GPU availability...\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"⚠ No GPU detected. Training will run on CPU.\")\n",
        "\n",
        "# Choose model size\n",
        "MODEL_SIZE = 'yolov8s.pt'   # small model (good accuracy + speed)\n",
        "\n",
        "# Load model\n",
        "model = YOLO(MODEL_SIZE)\n",
        "\n",
        "print(f\"\\n✓ Loaded YOLOv8 model: {MODEL_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsKbnjd2jBRy",
        "outputId": "2be1fb63-e6e4-4ca8-e28d-45ba3adb0b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING TRAINING (Optimized for 4GB GPU)\n",
            "================================================================================\n",
            "WARNING 'label_smoothing' is deprecated and will be removed in the future.\n",
            "Ultralytics 8.3.232  Python-3.10.0 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=False, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_dataset_single_class.yaml, degrees=10, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.3, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01, hsv_s=0.4, hsv_v=0.3, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.003, lrf=0.003, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=weapon_detection_single_class, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.4, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 328.5261.9 MB/s, size: 234.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\train\\labels.cache... 571 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 571/571 570.4Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 127.379.3 MB/s, size: 83.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 143/143 143.3Kit/s 0.0s\n",
            "Plotting labels to C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.003, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 512 train, 512 val\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      1.35G      1.759      2.227      2.009          3        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.5s0.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.2it/s 2.5s0.1s\n",
            "                   all        143        219      0.384      0.352      0.304     0.0899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      1.38G      1.939      2.004      2.187          3        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.4s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.4it/s 2.4s0.1s\n",
            "                   all        143        219      0.276      0.434      0.277      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      1.42G      1.924      1.951      2.183          3        512: 100% ━━━━━━━━━━━━ 143/143 4.1it/s 35.0s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.0it/s 2.6s0.2s\n",
            "                   all        143        219      0.381      0.416      0.305      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      1.46G      1.935      1.825      2.137          4        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.5s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.1it/s 2.5s0.2s\n",
            "                   all        143        219      0.383      0.425       0.37      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      1.49G      1.861      1.784      2.079          3        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.5s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.0it/s 2.6s0.2s\n",
            "                   all        143        219      0.466      0.442      0.369      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      1.57G      1.789      1.674      2.012          5        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.9s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 6.8it/s 2.6s0.2s\n",
            "                   all        143        219      0.467      0.457       0.36      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100       1.6G      1.768      1.643      2.002         13        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 35.8s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 7.0it/s 2.6s0.2s\n",
            "                   all        143        219      0.516      0.443      0.401      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      1.61G      1.652      1.549       1.93          4        512: 100% ━━━━━━━━━━━━ 143/143 4.0it/s 36.1s0.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 6.6it/s 2.7s0.2s\n",
            "                   all        143        219      0.558      0.543      0.508      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      1.61G      1.713      1.551      1.941          6        512: 100% ━━━━━━━━━━━━ 143/143 3.5it/s 40.3s0.5ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.2it/s 4.3s0.3s\n",
            "                   all        143        219      0.603      0.548      0.544      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      1.61G      1.661      1.544        1.9          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.594      0.543      0.529       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      1.61G      1.646      1.469      1.862          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.7it/s 3.8s0.3s\n",
            "                   all        143        219      0.673      0.499      0.524      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      1.61G      1.605      1.383      1.859          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.1s0.3s\n",
            "                   all        143        219      0.604       0.58      0.563      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      1.61G      1.604      1.439      1.815          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.647      0.511       0.57      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      1.68G      1.554      1.403      1.801          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.595      0.562      0.567      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      1.77G      1.519      1.342       1.76          4        512: 100% ━━━━━━━━━━━━ 143/143 2.1it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219       0.64      0.621      0.608      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      1.95G      1.528      1.318      1.765          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.673      0.516      0.605       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      1.98G      1.469      1.339      1.719          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.7it/s 3.9s0.3s\n",
            "                   all        143        219      0.725      0.614      0.668      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      2.02G      1.488      1.295      1.728          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.3it/s 4.2s0.3s\n",
            "                   all        143        219       0.62      0.709      0.671      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      1.51G      1.482      1.245      1.726          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 4.0s0.3s\n",
            "                   all        143        219      0.574      0.612      0.586      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      1.55G       1.48      1.291      1.748          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.0s0.3s\n",
            "                   all        143        219      0.758      0.621       0.69      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      1.58G      1.469      1.253      1.728          7        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.585      0.653       0.64      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      1.62G       1.46       1.21      1.704          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219       0.64      0.662      0.657      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      1.65G      1.412      1.184      1.666          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.672      0.717      0.693       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      1.69G      1.453      1.198      1.711          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.785      0.651      0.701      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      1.73G      1.429      1.193      1.665          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.748      0.685      0.716      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      1.76G      1.365      1.081      1.626          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.782      0.623      0.713      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100       1.8G      1.418       1.16      1.669          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.702      0.666      0.688      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      1.88G       1.42      1.146      1.663          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.797      0.662      0.747      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      1.95G      1.352      1.088      1.604          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.809      0.694      0.763      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      1.96G      1.347      1.038       1.61          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.752      0.694      0.733      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      1.96G      1.338      1.023      1.587          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.779      0.691      0.755      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      1.96G      1.288       1.02      1.561          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.1s0.3s\n",
            "                   all        143        219      0.829      0.663      0.757      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      1.96G      1.309      1.013      1.567          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.759      0.721      0.784      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      1.96G      1.269     0.9852      1.517          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.786      0.703       0.76      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      1.96G      1.295     0.9947      1.552          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.763      0.748      0.775      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      1.96G      1.235     0.9485      1.493          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.824      0.689      0.745      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      1.96G      1.251     0.9514       1.54          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.795      0.726      0.765      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      1.96G      1.265     0.9611      1.516          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.807      0.731      0.786       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      1.96G      1.255     0.9358      1.513          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.767       0.79      0.806      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      1.96G      1.224     0.9356      1.499          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.783      0.749      0.787      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      1.96G      1.218      0.925      1.487          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.866      0.685      0.776      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      1.96G      1.215     0.9233      1.489          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219       0.78      0.708      0.767      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      1.96G      1.221     0.9127       1.49          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219       0.78       0.74      0.778      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      1.96G      1.183     0.9072      1.461          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.857      0.739      0.822      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      1.96G      1.197     0.9049      1.474          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.794      0.735      0.797      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      1.96G      1.137     0.8319      1.446          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.857      0.744      0.813      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      1.96G      1.232     0.8898      1.479         10        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.857      0.737      0.808      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      1.96G      1.153     0.8275       1.45          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.826      0.776      0.813      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      1.96G      1.207     0.8455      1.475         16        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.845      0.772      0.817      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100       2.1G      1.162     0.8119      1.438          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.856      0.744      0.816      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      1.55G      1.152     0.8232      1.431         23        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.876      0.795      0.837      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100      1.55G      1.136     0.8104       1.42          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 4.0s0.3s\n",
            "                   all        143        219      0.917      0.759      0.849      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      1.58G      1.101     0.8092      1.407          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.852      0.781      0.844      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      1.62G      1.072     0.7805      1.376          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.849      0.772      0.823      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      1.66G      1.103     0.7887      1.414          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.901      0.786      0.854      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      1.69G      1.063     0.7535      1.355          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.874      0.831      0.887      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      1.73G      1.073     0.7612      1.374          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.857      0.795      0.855      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      1.91G      1.063     0.7592      1.368          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219       0.85      0.801      0.847      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      1.95G      1.099     0.7635      1.396          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.843      0.808      0.847      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      1.98G      1.068     0.7523      1.376          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.1s0.3s\n",
            "                   all        143        219      0.859      0.744      0.833      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      1.99G      1.051     0.7295      1.352          7        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 4.0s0.3s\n",
            "                   all        143        219      0.838      0.779      0.833      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      1.99G      1.052      0.716       1.35          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.861      0.799      0.858      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      1.99G      1.022     0.7129      1.325          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.926      0.803      0.865      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      1.99G      0.992     0.6753      1.318          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.884      0.763      0.848      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      1.99G     0.9977      0.675      1.309          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.866      0.785      0.843      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      1.99G      0.999     0.6796      1.314          9        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.3it/s 4.2s0.3s\n",
            "                   all        143        219      0.862      0.799      0.849      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      1.99G     0.9776     0.6704       1.29          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.7it/s 3.9s0.3s\n",
            "                   all        143        219      0.896      0.781       0.86      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      1.99G     0.9495      0.643      1.279          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.7it/s 3.9s0.3s\n",
            "                   all        143        219      0.876      0.805      0.859      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      1.99G     0.9554     0.6398      1.282          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.868      0.831      0.858      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      1.99G     0.9577     0.6237      1.288          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.867      0.804      0.858      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      1.99G     0.9463     0.6047      1.289          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.885      0.817      0.865      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      1.99G     0.9434     0.6203      1.268          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.1s0.3s\n",
            "                   all        143        219      0.884      0.808      0.857      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      1.99G     0.9297     0.6398      1.272          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219       0.91      0.787      0.874      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      1.99G     0.9221     0.6229      1.265          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.906      0.804      0.873      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      1.99G     0.9138     0.6096      1.256          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.905      0.808      0.881      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      1.99G     0.9067     0.5937      1.252          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.889      0.839      0.876      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      1.99G     0.9253     0.6227      1.269          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.918      0.831      0.885      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100      1.99G     0.8849     0.5861      1.222          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.909      0.819      0.885      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      1.99G      0.854     0.5826      1.221          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:100.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 4.0s0.3s\n",
            "                   all        143        219       0.85      0.836      0.879      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      1.99G     0.8621     0.5908      1.221          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.932      0.804      0.885      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100      2.02G      0.858     0.5744      1.223          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.936      0.807      0.881       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100      1.56G      0.883     0.5784      1.236          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.897      0.808      0.872      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      1.56G     0.8643     0.5752      1.216          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.918      0.814      0.879      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      1.59G     0.8558     0.5462      1.197          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.937      0.826      0.875      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      1.63G     0.8585     0.5669      1.224          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.923      0.819      0.871      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100      1.66G     0.8321     0.5518      1.196          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.916      0.826      0.875      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100       1.7G     0.8289      0.547       1.19          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.919      0.831      0.872      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100      1.73G     0.8253     0.5456      1.178          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.939      0.837      0.882      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100      1.92G     0.8352     0.5386      1.189          6        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.931      0.836      0.883      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      1.96G     0.8379     0.5406      1.176          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.923      0.826       0.88      0.598\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      1.99G     0.8255     0.5385       1.19          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.913      0.822      0.875      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      1.99G     0.8221     0.5399      1.184          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.917      0.822      0.876      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100      1.99G     0.8209     0.5383      1.181          8        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.922      0.813      0.881      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100      1.99G     0.8242     0.5351      1.178          5        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.928      0.821      0.879      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      1.99G     0.8161     0.5328      1.182          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.0s0.3s\n",
            "                   all        143        219      0.927      0.808      0.879      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      1.99G     0.8086     0.5372      1.183          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 4.0s0.3s\n",
            "                   all        143        219      0.917      0.826       0.88      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      1.99G     0.8184     0.5377      1.192         12        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:120.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.923      0.817      0.879      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      1.99G     0.8245     0.5354      1.196          3        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:130.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.928       0.82      0.881      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100      1.99G     0.8059     0.5327       1.18          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.5it/s 4.0s0.3s\n",
            "                   all        143        219      0.919      0.832      0.881      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100      1.99G     0.8284     0.5265      1.191          4        512: 100% ━━━━━━━━━━━━ 143/143 2.0it/s 1:110.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.6it/s 3.9s0.3s\n",
            "                   all        143        219      0.916      0.826      0.881        0.6\n",
            "\n",
            "100 epochs completed in 2.019 hours.\n",
            "Optimizer stripped from C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\\weights\\last.pt, 22.5MB\n",
            "Optimizer stripped from C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\\weights\\best.pt, 22.5MB\n",
            "\n",
            "Validating C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\\weights\\best.pt...\n",
            "Ultralytics 8.3.232  Python-3.10.0 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 18/18 4.4it/s 4.1s0.3s\n",
            "                   all        143        219      0.914      0.822      0.875      0.604\n",
            "Speed: 0.4ms preprocess, 21.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\weapon_detection_single_class\u001b[0m\n",
            "\n",
            "✓ Training completed!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 7: Train the Model (4GB GPU Safe Settings)\n",
        "# ============================================================================\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING TRAINING (Optimized for 4GB GPU)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use YOLOv8-nano (very light)\n",
        "MODEL_SIZE = \"yolov8s.pt\"\n",
        "model = YOLO(MODEL_SIZE)\n",
        "\n",
        "yaml_path = os.path.join(WORK_DIR, \"weapon_dataset_single_class.yaml\")\n",
        "\n",
        "results = model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=100,            \n",
        "    imgsz=512,            # lighter than 640\n",
        "    batch=4,              # small batch for 4GB GPU\n",
        "    patience=20,\n",
        "    device=0,\n",
        "    workers=1,\n",
        "    project=WORK_DIR,\n",
        "    name=\"weapon_detection_single_class\",\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.003,\n",
        "    lrf=0.003,\n",
        "    weight_decay=0.0005,\n",
        "    cos_lr=True,\n",
        "    label_smoothing=0.05,\n",
        "    \n",
        "    # LIGHT AUGMENTATIONS (GPU friendly)\n",
        "    mosaic=0.0,           \n",
        "    mixup=0.0,\n",
        "    copy_paste=False,\n",
        "    fliplr=0.3,\n",
        "    hsv_h=0.01,\n",
        "    hsv_s=0.4,\n",
        "    hsv_v=0.3,\n",
        "    degrees=10,\n",
        "    scale=0.4,\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYwP60qf2HJI",
        "outputId": "b9c6b30b-2ccb-45b2-b5b9-6ab28f370c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running validation on trained model...\n",
            "Ultralytics 8.3.232  Python-3.10.0 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Jiya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py\", line 247, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"C:\\Users\\Jiya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"C:\\Users\\Jiya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n",
            "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
            "BrokenPipeError: [WinError 232] The pipe is being closed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.3 ms, read: 186.8262.6 MB/s, size: 497.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\labels.cache... 143 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 143/143 35.7Kit/s 0.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 36/36 13.2it/s 2.7s0.1s\n",
            "                   all        143        219      0.919      0.826      0.878      0.604\n",
            "Speed: 1.1ms preprocess, 11.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\runs\\detect\\val\u001b[0m\n",
            "\n",
            "Validation Results:\n",
            "mAP50:     0.8775\n",
            "mAP50-95:  0.6036\n",
            "Precision: 0.9188\n",
            "Recall:    0.8263\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: Evaluate Model Performance (Local VS Code)\n",
        "# ============================================================================\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "print(\"\\nRunning validation on trained model...\")\n",
        "\n",
        "# Load your trained best model\n",
        "best_model_path = os.path.join(\n",
        "    WORK_DIR,\n",
        "    \"weapon_detection_single_class\",\n",
        "    \"weights\",\n",
        "    \"best.pt\"\n",
        ")\n",
        "\n",
        "# Safety check\n",
        "assert os.path.exists(best_model_path), \"❌ best.pt not found! Training may not have finished.\"\n",
        "\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "# Run validation\n",
        "metrics = model.val(\n",
        "    data=os.path.join(WORK_DIR, \"weapon_dataset_single_class.yaml\"),\n",
        "    imgsz=512,\n",
        "    batch=4,\n",
        "    device=0\n",
        ")\n",
        "\n",
        "# Print metrics safely\n",
        "print(\"\\nValidation Results:\")\n",
        "print(f\"mAP50:     {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOatsMAY2Z0D",
        "outputId": "497d40a9-ffaf-47ce-d360-0f542270c5dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing on 5 sample images...\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_35.jpeg: 384x640 1 Sniper, 70.0ms\n",
            "Speed: 2.4ms preprocess, 70.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_35.jpeg\n",
            "  Detections: 1\n",
            "    - Sniper: 0.55\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_19.jpeg: 384x640 1 Sword, 25.1ms\n",
            "Speed: 2.9ms preprocess, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_19.jpeg\n",
            "  Detections: 1\n",
            "    - Sword: 0.81\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_9.jpeg: 448x640 5 Swords, 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_9.jpeg\n",
            "  Detections: 5\n",
            "    - Sword: 0.57\n",
            "    - Sword: 0.50\n",
            "    - Sword: 0.44\n",
            "    - Sword: 0.38\n",
            "    - Sword: 0.30\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_54.jpeg: 384x640 1 Sword, 1 Sniper, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_54.jpeg\n",
            "  Detections: 2\n",
            "    - Sniper: 0.47\n",
            "    - Sword: 0.34\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_43.png: 192x640 1 Sword, 119.7ms\n",
            "Speed: 14.5ms preprocess, 119.7ms inference, 1.8ms postprocess per image at shape (1, 3, 192, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_43.png\n",
            "  Detections: 1\n",
            "    - Sword: 0.57\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: Test on Sample Images\n",
        "# ============================================================================\n",
        "\n",
        "# Get some validation images for testing\n",
        "val_image_files = [f for f in os.listdir(val_images) if f.endswith(('.jpg', '.png', '.jpeg'))][:5]\n",
        "\n",
        "print(f\"\\nTesting on {len(val_image_files)} sample images...\")\n",
        "\n",
        "for img_file in val_image_files:\n",
        "    img_path = os.path.join(val_images, img_file)\n",
        "\n",
        "    # Run prediction\n",
        "    results = model.predict(\n",
        "        source=img_path,\n",
        "        conf=0.25,        # Confidence threshold\n",
        "        iou=0.45,         # NMS IoU threshold\n",
        "        save=True,        # Save results\n",
        "        project=WORK_DIR,\n",
        "        name='predictions',\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\nProcessed: {img_file}\")\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"  Detections: {len(results[0].boxes)}\")\n",
        "        for box in results[0].boxes:\n",
        "            conf = box.conf[0].item()\n",
        "            cls = int(box.cls[0].item())\n",
        "            print(f\"    - {names[cls]}: {conf:.2f}\")\n",
        "    else:\n",
        "        print(\"  No weapons detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5Xz02e2gTi",
        "outputId": "d21b9498-8429-4b16-edd0-e6eda19a5820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing on sample validation images...\n",
            "\n",
            "Testing on 5 images...\n",
            "\n",
            "image 1/1 C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\images\\Automatic Rifle_13.jpeg: 288x512 1 weapon, 35.5ms\n",
            "Speed: 5.8ms preprocess, 35.5ms inference, 30.9ms postprocess per image at shape (1, 3, 288, 512)\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_13.jpeg\n",
            "  Detections: 1\n",
            "    - weapon: 0.91\n",
            "\n",
            "image 1/1 C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\images\\Automatic Rifle_19.jpeg: 320x512 1 weapon, 45.4ms\n",
            "Speed: 2.2ms preprocess, 45.4ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 512)\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_19.jpeg\n",
            "  Detections: 1\n",
            "    - weapon: 0.92\n",
            "\n",
            "image 1/1 C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\images\\Automatic Rifle_28.png: 384x512 (no detections), 38.3ms\n",
            "Speed: 1.1ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 512)\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_28.png\n",
            "  No weapon detected\n",
            "\n",
            "image 1/1 C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\images\\Automatic Rifle_35.jpeg: 288x512 1 weapon, 11.0ms\n",
            "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_35.jpeg\n",
            "  Detections: 1\n",
            "    - weapon: 0.89\n",
            "\n",
            "image 1/1 C:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\dataset\\weapon_detection\\val\\images\\Automatic Rifle_40.jpeg: 384x512 1 weapon, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
            "Results saved to \u001b[1mC:\\Users\\Jiya\\OneDrive - somaiya.edu\\Documents\\LY Project\\final run\\predictions\u001b[0m\n",
            "\n",
            "Processed: Automatic Rifle_40.jpeg\n",
            "  Detections: 1\n",
            "    - weapon: 0.87\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: Test on Sample Images (Local VS Code)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"\\nTesting on sample validation images...\")\n",
        "\n",
        "# Load trained model\n",
        "best_model_path = os.path.join(\n",
        "    WORK_DIR,\n",
        "    \"weapon_detection_single_class\",\n",
        "    \"weights\",\n",
        "    \"best.pt\"\n",
        ")\n",
        "\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "# Single class mapping\n",
        "names = [\"weapon\"]\n",
        "\n",
        "# Pick a few validation images\n",
        "val_image_files = [\n",
        "    f for f in os.listdir(val_images)\n",
        "    if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
        "][:5]\n",
        "\n",
        "print(f\"\\nTesting on {len(val_image_files)} images...\")\n",
        "\n",
        "# Create prediction output folder\n",
        "PRED_DIR = os.path.join(WORK_DIR, \"predictions\")\n",
        "os.makedirs(PRED_DIR, exist_ok=True)\n",
        "\n",
        "for img_file in val_image_files:\n",
        "    img_path = os.path.join(val_images, img_file)\n",
        "\n",
        "    # Run prediction\n",
        "    results = model.predict(\n",
        "        source=img_path,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        save=True,\n",
        "        project=WORK_DIR,\n",
        "        name=\"predictions\",\n",
        "        exist_ok=True,\n",
        "        device=0\n",
        "    )\n",
        "\n",
        "    print(f\"\\nProcessed: {img_file}\")\n",
        "\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"  Detections: {len(results[0].boxes)}\")\n",
        "        for box in results[0].boxes:\n",
        "            conf = float(box.conf[0])\n",
        "            print(f\"    - weapon: {conf:.2f}\")\n",
        "    else:\n",
        "        print(\"  No weapon detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDdq6f052vCr",
        "outputId": "a8ae445c-3f7c-4621-f8f7-82c3bf89e472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "USING YOUR TRAINED MODEL\n",
            "================================================================================\n",
            "\n",
            "Testing batch prediction on validation images...\n",
            "Processing 10 sample images from validation set...\n",
            "\n",
            "\n",
            "[1/10] Processing: Automatic Rifle_35.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_35.jpeg: 384x640 1 Sniper, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sniper: 1\n",
            "\n",
            "[2/10] Processing: Automatic Rifle_19.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_19.jpeg: 384x640 1 Sword, 31.9ms\n",
            "Speed: 3.8ms preprocess, 31.9ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sword: 1\n",
            "\n",
            "[3/10] Processing: Automatic Rifle_9.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_9.jpeg: 448x640 5 Swords, 28.4ms\n",
            "Speed: 4.0ms preprocess, 28.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 5 weapon(s):\n",
            "    - Sword: 5\n",
            "\n",
            "[4/10] Processing: Automatic Rifle_54.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_54.jpeg: 384x640 1 Sword, 1 Sniper, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 2 weapon(s):\n",
            "    - Sniper: 1\n",
            "    - Sword: 1\n",
            "\n",
            "[5/10] Processing: Automatic Rifle_43.png\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_43.png: 192x640 1 Sword, 18.4ms\n",
            "Speed: 2.4ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sword: 1\n",
            "\n",
            "[6/10] Processing: Automatic Rifle_50.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_50.jpeg: 416x640 6 Swords, 1 Sniper, 50.1ms\n",
            "Speed: 3.0ms preprocess, 50.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 7 weapon(s):\n",
            "    - Sword: 6\n",
            "    - Sniper: 1\n",
            "\n",
            "[7/10] Processing: Bazooka_86.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Bazooka_86.jpeg: 384x640 1 Sword, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sword: 1\n",
            "\n",
            "[8/10] Processing: Bazooka_70.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Bazooka_70.jpeg: 416x640 2 Swords, 27.4ms\n",
            "Speed: 1.7ms preprocess, 27.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 2 weapon(s):\n",
            "    - Sword: 2\n",
            "\n",
            "[9/10] Processing: Automatic Rifle_62.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_62.jpeg: 352x640 1 Sword, 47.6ms\n",
            "Speed: 1.9ms preprocess, 47.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sword: 1\n",
            "\n",
            "[10/10] Processing: Automatic Rifle_77.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Voilence Detection/dataset/weapon_detection/val/images/Automatic Rifle_77.jpeg: 384x640 1 Sword, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Voilence Detection/validation_predictions\u001b[0m\n",
            "  ✓ Found 1 weapon(s):\n",
            "    - Sword: 1\n",
            "\n",
            "================================================================================\n",
            "BATCH PREDICTION SUMMARY\n",
            "================================================================================\n",
            "Total images processed: 10\n",
            "Images with weapons detected: 10\n",
            "Images without weapons: 0\n",
            "Total weapon detections: 22\n",
            "Average detections per image: 2.20\n",
            "\n",
            "================================================================================\n",
            "HOW TO USE YOUR MODEL\n",
            "================================================================================\n",
            "\n",
            "# Load your trained model\n",
            "from ultralytics import YOLO\n",
            "model = YOLO('/content/drive/MyDrive/Voilence Detection/weapon_detection_run/weights/best.pt')\n",
            "\n",
            "# Predict on a single image\n",
            "results = model.predict('path/to/image.jpg', conf=0.25)\n",
            "\n",
            "# Predict on multiple images\n",
            "results = model.predict('path/to/folder/', conf=0.25)\n",
            "\n",
            "# Predict on video\n",
            "results = model.predict('path/to/video.mp4', conf=0.25)\n",
            "\n",
            "# Access detection results\n",
            "for r in results:\n",
            "    boxes = r.boxes  # Bounding boxes\n",
            "    for box in boxes:\n",
            "        cls = int(box.cls[0])  # Class ID\n",
            "        conf = box.conf[0]     # Confidence\n",
            "        weapon = ['Sword', 'Shotgun', 'Sniper'][cls]  # Weapon name\n",
            "        print(f\"Detected: {weapon} ({conf:.2%} confidence)\")\n",
            "\n",
            "# Adjust confidence threshold based on your needs:\n",
            "# - Higher (0.5-0.7): Fewer false positives, might miss some weapons\n",
            "# - Lower (0.15-0.25): Catch more weapons, might have false positives\n",
            "# - Recommended: 0.25-0.4 for security applications\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# STEP 10: Load and Use Trained Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"USING YOUR TRAINED MODEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load the best trained model\n",
        "trained_model = YOLO(best_model_path)\n",
        "\n",
        "# Comprehensive prediction function\n",
        "def predict_weapons(image_path, conf_threshold=0.25, save_result=True):\n",
        "    \"\"\"\n",
        "    Detect weapons in an image with detailed output\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image or directory\n",
        "        conf_threshold: Confidence threshold for detections (0.0-1.0)\n",
        "        save_result: Whether to save annotated image\n",
        "\n",
        "    Returns:\n",
        "        results: Detection results with weapon information\n",
        "    \"\"\"\n",
        "    results = trained_model.predict(\n",
        "        source=image_path,\n",
        "        conf=conf_threshold,\n",
        "        iou=0.45,\n",
        "        save=save_result,\n",
        "        project=WORK_DIR,\n",
        "        name='weapon_predictions',\n",
        "        exist_ok=True,\n",
        "        show_labels=True,\n",
        "        show_conf=True,\n",
        "        line_width=2\n",
        "    )\n",
        "\n",
        "    # Print detailed detection info\n",
        "    for r in results:\n",
        "        if len(r.boxes) > 0:\n",
        "            print(f\"\\n🎯 Detected {len(r.boxes)} weapon(s) in image:\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Count each weapon type\n",
        "            from collections import Counter\n",
        "            weapon_counts = Counter()\n",
        "\n",
        "            for box in r.boxes:\n",
        "                conf = box.conf[0].item()\n",
        "                cls = int(box.cls[0].item())\n",
        "                weapon_name = names[cls]\n",
        "                weapon_counts[weapon_name] += 1\n",
        "\n",
        "                # Get bounding box coordinates\n",
        "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "\n",
        "                print(f\"  • {weapon_name}\")\n",
        "                print(f\"    Confidence: {conf:.2%}\")\n",
        "                print(f\"    Location: ({int(x1)}, {int(y1)}) to ({int(x2)}, {int(y2)})\")\n",
        "                print()\n",
        "\n",
        "            print(\"Summary:\")\n",
        "            for weapon, count in weapon_counts.most_common():\n",
        "                print(f\"  {weapon}: {count}\")\n",
        "        else:\n",
        "            print(f\"\\n✓ No weapons detected in image\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test batch prediction on validation set\n",
        "print(\"\\nTesting batch prediction on validation images...\")\n",
        "\n",
        "# Get some validation images for testing\n",
        "val_image_files = [f for f in os.listdir(val_images) if f.endswith(('.jpg', '.png', '.jpeg'))][:10]\n",
        "\n",
        "print(f\"Processing {len(val_image_files)} sample images from validation set...\\n\")\n",
        "\n",
        "total_detections = 0\n",
        "images_with_weapons = 0\n",
        "\n",
        "for i, img_file in enumerate(val_image_files, 1):\n",
        "    img_path = os.path.join(val_images, img_file)\n",
        "    print(f\"\\n[{i}/{len(val_image_files)}] Processing: {img_file}\")\n",
        "\n",
        "    results = trained_model.predict(\n",
        "        source=img_path,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        save=True,\n",
        "        project=WORK_DIR,\n",
        "        name='validation_predictions',\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    if len(results[0].boxes) > 0:\n",
        "        images_with_weapons += 1\n",
        "        num_weapons = len(results[0].boxes)\n",
        "        total_detections += num_weapons\n",
        "\n",
        "        print(f\"  ✓ Found {num_weapons} weapon(s):\")\n",
        "\n",
        "        # Group by weapon type\n",
        "        from collections import Counter\n",
        "        weapons_found = Counter()\n",
        "\n",
        "        for box in results[0].boxes:\n",
        "            conf = box.conf[0].item()\n",
        "            cls = int(box.cls[0].item())\n",
        "            weapon_name = names[cls]\n",
        "            weapons_found[weapon_name] += 1\n",
        "\n",
        "        for weapon, count in weapons_found.most_common():\n",
        "            print(f\"    - {weapon}: {count}\")\n",
        "    else:\n",
        "        print(f\"  • No weapons detected\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BATCH PREDICTION SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total images processed: {len(val_image_files)}\")\n",
        "print(f\"Images with weapons detected: {images_with_weapons}\")\n",
        "print(f\"Images without weapons: {len(val_image_files) - images_with_weapons}\")\n",
        "print(f\"Total weapon detections: {total_detections}\")\n",
        "print(f\"Average detections per image: {total_detections/len(val_image_files):.2f}\")\n",
        "\n",
        "# Example usage function\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"HOW TO USE YOUR MODEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "example_code = f'''\n",
        "# Load your trained model\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('{best_model_path}')\n",
        "\n",
        "# Predict on a single image\n",
        "results = model.predict('path/to/image.jpg', conf=0.25)\n",
        "\n",
        "# Predict on multiple images\n",
        "results = model.predict('path/to/folder/', conf=0.25)\n",
        "\n",
        "# Predict on video\n",
        "results = model.predict('path/to/video.mp4', conf=0.25)\n",
        "\n",
        "# Access detection results\n",
        "for r in results:\n",
        "    boxes = r.boxes  # Bounding boxes\n",
        "    for box in boxes:\n",
        "        cls = int(box.cls[0])  # Class ID\n",
        "        conf = box.conf[0]     # Confidence\n",
        "        weapon = {names}[cls]  # Weapon name\n",
        "        print(f\"Detected: {{weapon}} ({{conf:.2%}} confidence)\")\n",
        "\n",
        "# Adjust confidence threshold based on your needs:\n",
        "# - Higher (0.5-0.7): Fewer false positives, might miss some weapons\n",
        "# - Lower (0.15-0.25): Catch more weapons, might have false positives\n",
        "# - Recommended: 0.25-0.4 for security applications\n",
        "'''\n",
        "\n",
        "print(example_code)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
